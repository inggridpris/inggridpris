{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inggridpris/inggridpris/blob/main/Data_Science_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWa7G3q2EAcM"
      },
      "source": [
        "# Quick Look Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsGjHaFtENmo"
      },
      "source": [
        "Qualified for the Loan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8fmid7WEMHb"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raQe4NWDHQNy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKMHqpM0FW2M"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvpQozOsFZBq"
      },
      "outputs": [],
      "source": [
        "print('Numpy Version:', np.__version__)\n",
        "print('Pandas Version:', pd.__version__)\n",
        "print('Seaborn Version:', sns.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDwqUn5gFisg"
      },
      "source": [
        "## Mengubah parameter default matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDI-6hpSFvql"
      },
      "outputs": [],
      "source": [
        "from matplotlib import rcParams\n",
        "rcParams['figure.figsize'] = 12, 4\n",
        "rcParams['lines.linewidth'] = 3\n",
        "rcParams['xtick.labelsize'] = 'x-large'\n",
        "rcParams['ytick.labelsize'] = 'x-large'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIm0TYcjF0Gp"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXjxA22PF6_c"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv('/content/drive/My Drive/Data Science Test/app_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DFTo6LX_sxW"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kf5HKEItH8Di"
      },
      "outputs": [],
      "source": [
        "df1= pd.read_csv('/content/drive/My Drive/Data Science Test/app_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtgwoD_iGCzE"
      },
      "outputs": [],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTeqpSVkIk0A"
      },
      "outputs": [],
      "source": [
        "df3= pd.read_csv('/content/drive/My Drive/Data Science Test/installment_payment.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2wBwGbZ8_CK"
      },
      "outputs": [],
      "source": [
        "df3.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz7UX67fItxi"
      },
      "outputs": [],
      "source": [
        "df4= pd.read_csv('/content/drive/My Drive/Data Science Test/prev_app.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73bOnlXtFp_K"
      },
      "outputs": [],
      "source": [
        "df4.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0EJJRjTJKhf"
      },
      "source": [
        "#STAGE 1 - Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfZSWEGHS2T0"
      },
      "source": [
        "## 1. Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11SHwP6EJQFd"
      },
      "outputs": [],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGi4EEcQTEUx"
      },
      "source": [
        "Hasil Pengamatan:\n",
        "*   Data terdiri dari 61053 baris.\n",
        "*   Terdapat 3 jenis tipe data yaitu float, int, dan object.\n",
        "*   Terdapat missing value pada beberapa kolom\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGjUV30fTAZR"
      },
      "source": [
        "## 2. Cuplikan Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64STrthwSxc_"
      },
      "outputs": [],
      "source": [
        "df1.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FDynIwiUlxm"
      },
      "source": [
        "Hasil Pengamatan:\n",
        "Terdapat data yang tidak diberikan nilai pada kolom tertentu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa65sdMjVBU1"
      },
      "source": [
        "## 3. Statistical Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r4pYMHVVzqo"
      },
      "source": [
        "### Pick + Separate Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX6_c_5KVC_N"
      },
      "outputs": [],
      "source": [
        "df2= df1.drop(['Unnamed: 0','EXT_SCORE_1','EXT_SCORE_2','EXT_SCORE_3'],axis='columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwYhhXQZVQya"
      },
      "outputs": [],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9j8N-o83NBR"
      },
      "outputs": [],
      "source": [
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3RRhetb3NE0"
      },
      "outputs": [],
      "source": [
        "nums = ['LN_ID','NUM_CHILDREN','INCOME','APPROVED_CREDIT','ANNUITY','PRICE','DAYS_AGE','DAYS_WORK','DAYS_REGISTRATION','DAYS_ID_CHANGE','HOUR_APPLY']\n",
        "cats = ['TARGET','CONTRACT_TYPE','GENDER','EDUCATION','INCOME_TYPE','FAMILY_STATUS','HOUSING_TYPE','WEEKDAYS_APPLY','ORGANIZATION_TYPE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf9DawL8GDge"
      },
      "outputs": [],
      "source": [
        "df2[nums].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZCq65O9GDxO"
      },
      "outputs": [],
      "source": [
        "df2_cats = df2[cats].astype('category').copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GdluQXrGD69"
      },
      "outputs": [],
      "source": [
        "df2_cats.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB-nO7fJH5g4"
      },
      "outputs": [],
      "source": [
        "df2.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdTuRxSuVJn-"
      },
      "source": [
        "## 4. Value Counting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gzo5O0q3IO6I"
      },
      "outputs": [],
      "source": [
        "for col in cats:\n",
        "  print(f'''Value count kolom {col}:''')\n",
        "  print(df2[col].value_counts())\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LcJv_BoVOTm"
      },
      "source": [
        "##5. Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CduQik1SKje_"
      },
      "outputs": [],
      "source": [
        "features = nums\n",
        "plt.figure(figsize=(8, 10))\n",
        "for i in range(0, len(features)):\n",
        "    plt.subplot(4, 3, i+1)\n",
        "    sns.boxplot(y=df1[features[i]], color='blue', orient='v')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBzLuDbIKjQS"
      },
      "outputs": [],
      "source": [
        "features = nums\n",
        "plt.figure(figsize=(12, 10))\n",
        "for i in range(0, len(nums)):\n",
        "    plt.subplot(4, 3, i+1)\n",
        "    sns.kdeplot(x=df2[features[i]], color='GREEN')\n",
        "    plt.xlabel(features[i])\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wee91aXoKjMn"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "for i in range(0, len(cats)):\n",
        "    plt.subplot(7, 2, i+1)\n",
        "    sns.countplot(x = df2[cats[i]], color='brown', orient='v')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-99bOQwVN-7"
      },
      "source": [
        "##6. Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m2FABY0TwFb"
      },
      "outputs": [],
      "source": [
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVD-VGcVKlYZ"
      },
      "outputs": [],
      "source": [
        "df2.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymoh5_oiKlN3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(df2.corr(), cmap='Blues', annot=True, fmt='.2f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNnmVxp_Khix"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "sns.pairplot(df2[nums], diag_kind='kde')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOS8mpILJZse"
      },
      "source": [
        "# STAGE 2 - Pre Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7DE3xFXCVR1"
      },
      "source": [
        "##1. Data Cleansing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-CvGeFhCbcz"
      },
      "source": [
        "### Handling missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btji69swDBTh"
      },
      "outputs": [],
      "source": [
        "df2.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7X88FjvEy6N"
      },
      "outputs": [],
      "source": [
        "df2_new=df2.dropna(subset=['ANNUITY','PRICE'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djch8ddiVAmo"
      },
      "source": [
        "Untuk data yang hilang, kita mendrop sebanyak 62 data di table annuity dan sebanyak 1 di kolom price. Data dihilangkan karena tidak berdampak terlalu besar dengan dataset yang ada sehingga bisa untuk di drop saja."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn5JMTIXFt-F"
      },
      "outputs": [],
      "source": [
        "df2_new.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7YOUgPyFtvk"
      },
      "outputs": [],
      "source": [
        "df2_new.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKggAE_jC3KJ"
      },
      "source": [
        "### Handling Duplicated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmGP3zq-Cao2"
      },
      "outputs": [],
      "source": [
        "df2_new.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTRwn9HpVwEk"
      },
      "source": [
        "Pada dataset ini tidak ada data duplicate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSERy9ZxHIZ0"
      },
      "source": [
        "## Log Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLwonAUqM8ZL"
      },
      "outputs": [],
      "source": [
        "df2_new['LOG_LN_ID']= np.log(df2_new['LN_ID']+np.finfo(float).eps)\n",
        "df2_new['LOG_NUM_CHILDREN']= np.log(df2_new['NUM_CHILDREN']+np.finfo(float).eps)\n",
        "df2_new['LOG_INCOME']= np.log(df2_new['INCOME']+np.finfo(float).eps)\n",
        "df2_new['LOG_APPROVED_CREDIT']= np.log(df2_new['APPROVED_CREDIT']+np.finfo(float).eps)\n",
        "df2_new['LOG_ANNUITY']= np.log(df2_new['ANNUITY']+np.finfo(float).eps)\n",
        "df2_new['LOG_PRICE']= np.log(df2_new['PRICE']+np.finfo(float).eps)\n",
        "df2_new['LOG_DAYS_AGE']= np.log(df2_new['DAYS_AGE']+np.finfo(float).eps)\n",
        "df2_new['LOG_DAYS_WORK']= np.log(df2_new['DAYS_WORK']+np.finfo(float).eps)\n",
        "df2_new['LOG_DAYS_REGISTRATION']= np.log(df2_new['DAYS_REGISTRATION']+np.finfo(float).eps)\n",
        "df2_new['LOG_DAYS_ID_CHANGE']= np.log(df2_new['DAYS_ID_CHANGE']+np.finfo(float).eps)\n",
        "df2_new['LOG_HOUR_APPLY']= np.log(df2_new['HOUR_APPLY']+np.finfo(float).eps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRfGaX9DZ8Qu"
      },
      "source": [
        "Pada dataset ini, digunakan log transformasi karena pada bagian univariate analysis, kolom numerik lebih ke skew kanan sehingga menggunakan log transformasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_IW-duNMCia"
      },
      "outputs": [],
      "source": [
        "df2_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMlspHsQI7B0"
      },
      "outputs": [],
      "source": [
        "log=['LOG_LN_ID','LOG_NUM_CHILDREN','LOG_INCOME','LOG_APPROVED_CREDIT','LOG_ANNUITY','LOG_PRICE','LOG_DAYS_AGE','LOG_DAYS_WORK','LOG_DAYS_REGISTRATION','LOG_DAYS_ID_CHANGE','LOG_HOUR_APPLY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NasgYQ3DI6_y"
      },
      "outputs": [],
      "source": [
        "features = log\n",
        "plt.figure(figsize=(12, 10))\n",
        "for i in range(0, len(log)):\n",
        "    plt.subplot(4, 3, i+1)\n",
        "    sns.kdeplot(x=df2_new[features[i]], color='GREEN')\n",
        "    plt.xlabel(features[i])\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2TyUpeqaRaw"
      },
      "source": [
        "Dari hasil log, di dapatkan bahwa LOG_DAYS_AGE','LOG_DAYS_WORK','LOG_DAYS_REGISTRATION','LOG_DAYS_ID_CHANGE','LOG_LN_ID', 'LOG_HOUR_APPLY' , memiliki hasil yang tidak baik sehingga pada kolom ini, kita tidak melakukan apa-apa dan memakai kolom awal.\n",
        "Untuk yang lainnya, kita memakai log karena datanya menjadi berdistribusi normal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwbZ2WGd5AT7"
      },
      "source": [
        "### Drop Kolom Lama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvAg-zh0rntL"
      },
      "outputs": [],
      "source": [
        "df2_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBfjsPo9I69D"
      },
      "outputs": [],
      "source": [
        "df2_new1 = df2_new.drop(columns=['LOG_DAYS_AGE','LOG_DAYS_WORK','LOG_DAYS_REGISTRATION','LOG_DAYS_ID_CHANGE','LOG_LN_ID','INCOME','NUM_CHILDREN','LOG_HOUR_APPLY','APPROVED_CREDIT','ANNUITY','PRICE'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrPPlYBea5Si"
      },
      "source": [
        "Disini dilakukan drop kolom yang tidak diperlukan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQU-8TYlqx0_"
      },
      "outputs": [],
      "source": [
        "df2_new1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-BGPzfUI62q"
      },
      "outputs": [],
      "source": [
        "df2_new1.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9weDMz5x-US4"
      },
      "source": [
        "### Feature Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8K_0J-o0ZP1"
      },
      "outputs": [],
      "source": [
        "mapping_gender={'M':0, 'F':1}\n",
        "df2_new1['GENDER']=df2_new1['GENDER'].map(mapping_gender)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxgHhYAn0ZNr"
      },
      "outputs": [],
      "source": [
        "mapping_education={'Secondary / secondary special':0, 'Higher education':1,'Incomplete higher':2,'Lower secondary':3,'Academic degree':4}\n",
        "df2_new1['EDUCATION']=df2_new1['EDUCATION'].map(mapping_education)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oP70-df0ZLe"
      },
      "outputs": [],
      "source": [
        "mapping_contract={'Cash loans':0, 'Revolving loans':1}\n",
        "df2_new1['CONTRACT_TYPE']=df2_new1['CONTRACT_TYPE'].map(mapping_contract)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_YtKmCP4BqI"
      },
      "outputs": [],
      "source": [
        "df2_new1['FAMILY_STATUS'].replace('Civil marriage', 'Married', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0vtkTRMxTPs"
      },
      "outputs": [],
      "source": [
        "df2_new1['INCOME_TYPE'].replace('Businessman', 'Working', inplace=True)\n",
        "df2_new1['INCOME_TYPE'].replace('Student', 'Unemployed', inplace=True)\n",
        "df2_new1['INCOME_TYPE'].replace('Pensioner', 'Unemployed', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp0U5bEagEfC"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Business Entity Type 3', 'Business Entity', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Business Entity Type 2', 'Business Entity', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Business Entity Type 1', 'Business Entity', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHRErmG4h3_y"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Trade: type 7', 'Trade', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Trade: type 6', 'Trade', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Trade: type 1', 'Trade', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Trade: type 4', 'Trade', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Trade: type 5', 'Trade', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Trade: type 2', 'Trade', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Trade: type 3', 'Trade', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXn0TIWmh369"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Transport: type 4', 'Transport: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Transport: type 2', 'Transport: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Transport: type 3', 'Transport: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Transport: type 1', 'Transport: type', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f_TLDqBxZ1l"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 9', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 1', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 10', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 11', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 12', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 13', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 2', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 4', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 5', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 6', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 7', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 8', 'Industry: type', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Industry: type 3', 'Industry: type', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1HxPU41h31-"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('University', 'School', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Kindergarten', 'School', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir6yxR5K2sh1"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Bank', 'Work', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Construction', 'Work', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Agriculture', 'Work', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Electricity', 'Work', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_ZtBzbfh3v6"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Mobile', 'Telecom', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Advertising', 'Telecom', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neCUJpm5h3el"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Cleaning', 'Services', inplace=True) \n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Legal Services', 'Services', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Postal', 'Services', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Restaurant', 'Services', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9p9pk8zOh3QN"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Police', 'Military', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlimUd_uop0t"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Security Ministries', 'Government', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpGms0D5pz75"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Hotel', 'Housing', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Realtor', 'Housing', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfDCKaYcqhAQ"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Culture', 'Religion', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44uNFwlS1Oh4"
      },
      "outputs": [],
      "source": [
        "df2_new1['ORGANIZATION_TYPE'].replace('Insurance', 'Health', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Medicine', 'Health', inplace=True)\n",
        "df2_new1['ORGANIZATION_TYPE'].replace('Emergency', 'Health', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOi4gmn4xv5n"
      },
      "outputs": [],
      "source": [
        "cats_one = ['INCOME_TYPE', 'FAMILY_STATUS', 'HOUSING_TYPE', 'WEEKDAYS_APPLY', 'ORGANIZATION_TYPE']\n",
        "for cats_one in ['INCOME_TYPE', 'FAMILY_STATUS', 'HOUSING_TYPE', 'WEEKDAYS_APPLY', 'ORGANIZATION_TYPE']:\n",
        "    onehots = pd.get_dummies(df2_new1[cats_one], prefix=cats_one)\n",
        "    df2_new1 = df2_new1.join(onehots)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4WZuBjXbBLa"
      },
      "source": [
        "Pada dataset ini dilakukan labeling dan onehotconding untuk mengubah kolom kategorikal menjadi data numerik.\n",
        "Sebelum dilakukan onehotcoding, dilakukan replace kata-kata yang memiliki pengertian sama digabungkan menjadi satu sehingga kolom yang dihasilkan tidak terlalu banyak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOz9ndsn0ZF7"
      },
      "outputs": [],
      "source": [
        "df2_new1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igLJ-b680ZDT"
      },
      "outputs": [],
      "source": [
        "df2_new2 = df2_new1.drop(columns=['INCOME_TYPE', 'FAMILY_STATUS', 'HOUSING_TYPE', 'WEEKDAYS_APPLY', 'ORGANIZATION_TYPE'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDjXMGMu0ZAX"
      },
      "outputs": [],
      "source": [
        "df2_new2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXigWl4v8PqI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xyKJZEvFMV5"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ya-59pQ98Pfg"
      },
      "outputs": [],
      "source": [
        "corrmat = df2_new2.corr() #menghitung korelasi dengan fungsi corr()\n",
        "top_corr_features = corrmat.index #menampilkan index\n",
        "plt.figure(figsize=(25,25)) #membuat plot dengan ukuran 20x20\n",
        "g=sns.heatmap(df2_new2[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\") #menampilkan heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JTGb93KI6qL"
      },
      "outputs": [],
      "source": [
        "a = corrmat['TARGET'] #mengambil nilai korelasi Revenue\n",
        "hasil = a[(a>0.05)|(a<-0.05)] #mengambil nilai korelasi yang lebih dari 0.1\n",
        "hasil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnBGo-iBbY-5"
      },
      "source": [
        "Dari hasil correlation, didapatkan 6 kolom yang memiliki korelasi kuat dengan kolon target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veaFNcVmA4Xz"
      },
      "outputs": [],
      "source": [
        "df2_new2[\"GENDER\"] = df2_new2[\"GENDER\"].astype(\"int\")\n",
        "df2_new2[\"TARGET\"] =df2_new2[\"TARGET\"].astype(\"int\")\n",
        "df2_new2[\"DAYS_AGE\"] = df2_new2[\"DAYS_AGE\"].astype(\"int\")\n",
        "df2_new2[\"DAYS_ID_CHANGE\"] =df2_new2[\"DAYS_ID_CHANGE\"].astype(\"int\")\n",
        "df2_new2[\"INCOME_TYPE_Unemployed\"] = df2_new2[\"INCOME_TYPE_Unemployed\"].astype(\"int\")\n",
        "df2_new2[\"INCOME_TYPE_Working\"] = df2_new2[\"INCOME_TYPE_Working\"].astype(\"int\")\n",
        "df2_new2[\"ORGANIZATION_TYPE_NA1\"] = df2_new2[\"ORGANIZATION_TYPE_NA1\"].astype(\"int\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apSVdmKB-FIo"
      },
      "outputs": [],
      "source": [
        "df_selection=df2_new2[['TARGET','GENDER','DAYS_AGE','DAYS_ID_CHANGE','INCOME_TYPE_Unemployed','INCOME_TYPE_Working','ORGANIZATION_TYPE_NA1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XqGhswEJevU"
      },
      "source": [
        "# STAGE 3 -  Modeling and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pu5Ixmg_E1F"
      },
      "source": [
        "### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF-rG1eM_bzt"
      },
      "outputs": [],
      "source": [
        "X = df_selection[['GENDER','DAYS_AGE','DAYS_ID_CHANGE','INCOME_TYPE_Unemployed','INCOME_TYPE_Working','ORGANIZATION_TYPE_NA1']]\n",
        "y = df_selection['TARGET']\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFRAtmf-_bl3"
      },
      "outputs": [],
      "source": [
        "df_selection['TARGET'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKp-3dnp_Qj9"
      },
      "source": [
        "## Class Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lceR8tMLHAl_"
      },
      "outputs": [],
      "source": [
        "from imblearn import under_sampling, over_sampling\n",
        "X_under, y_under = under_sampling.RandomUnderSampler().fit_resample(X_train, y_train)\n",
        "X_over, y_over = over_sampling.RandomOverSampler().fit_resample(X_train, y_train)\n",
        "X_over_SMOTE, y_over_SMOTE = over_sampling.SMOTE().fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QnATUVfJK3o"
      },
      "outputs": [],
      "source": [
        "print('Original')\n",
        "print(pd.Series(y).value_counts())\n",
        "print('\\n')\n",
        "print('UNDERSAMPLING')\n",
        "print(pd.Series(y_under).value_counts())\n",
        "print('\\n')\n",
        "print('OVERSAMPLING')\n",
        "print(pd.Series(y_over).value_counts())\n",
        "print('\\n')\n",
        "print('SMOTE')\n",
        "print(pd.Series(y_over_SMOTE).value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP73UOyh_QT6"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cnk8yKSI_DXs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def eval_classification(model):\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"Accuracy (Test Set): %.2f\" % accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision (Test Set): %.2f\" % precision_score(y_test, y_pred))\n",
        "    print(\"Recall (Test Set): %.2f\" % recall_score(y_test, y_pred))\n",
        "    print(\"F1-Score (Test Set): %.2f\" % f1_score(y_test, y_pred))\n",
        "    print('AUC:'+ str(roc_auc_score(y_test, y_pred)))\n",
        "\n",
        "def show_feature_importance(model):\n",
        "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "    ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.xlabel('score')\n",
        "    plt.ylabel('feature')\n",
        "    plt.title('feature importance score')\n",
        "\n",
        "def show_best_hyperparameter(model, hyperparameters):\n",
        "    for key, value in hyperparameters.items() :\n",
        "        print('Best '+key+':', model.get_params()[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cSvXt99K6PE"
      },
      "source": [
        "### 1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH7WrtJvLxzG"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "\n",
        "eval_classification(lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLAZDwDTLxql"
      },
      "outputs": [],
      "source": [
        "print('Train score: ' + str(lr.score(X_over_SMOTE, y_over_SMOTE))) #accuracy\n",
        "print('Test score: ' + str(lr.score(X_test, y_test))) #accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l5yxecMK_AH"
      },
      "source": [
        "#### Tuning Hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQPOkC5gMC9c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "# List Hyperparameters yang akan diuji\n",
        "solver = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2','l1', 'elasticnet', 'none']\n",
        "C = [100, 10, 1.0, 0.1, 0.01, 0.001, 0.0001]\n",
        "hyperparameters = dict(penalty=penalty, C=C, solver=solver )\n",
        "\n",
        "# Inisiasi model\n",
        "logres = LogisticRegression(random_state=42) # Init Logres dengan Gridsearch, cross validation = 5\n",
        "lr_tuned = RandomizedSearchCV(logres, hyperparameters, cv=5, random_state=42, scoring='recall')\n",
        "\n",
        "# Fitting Model & Evaluation\n",
        "lr_tuned.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "eval_classification(lr_tuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVi8_YabMCx5"
      },
      "outputs": [],
      "source": [
        "print('Train score: ' + str(lr.score(X_over_SMOTE, y_over_SMOTE))) #accuracy\n",
        "print('Test score: ' + str(lr.score(X_test, y_test))) #accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dVlxx5mN_Sm"
      },
      "outputs": [],
      "source": [
        "logres = LogisticRegression(penalty='l2', C=0.0001, solver='lbfgs', random_state=42)\n",
        "logres.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "y_pred = logres.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ0366kyODNT"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "feature_names = X_over_SMOTE.columns.to_list()\n",
        "\n",
        "#Get the scores\n",
        "score = logres.score(X_over_SMOTE.values, y_over_SMOTE)\n",
        "print(score)\n",
        "w0 = logres.intercept_[0]\n",
        "w = logres.coef_[0]\n",
        "\n",
        "feature_importance = pd.DataFrame(feature_names, columns = ['feature'])\n",
        "feature_importance['importance'] = pow(math.e, w)\n",
        "feature_importance = feature_importance.sort_values(by=['importance'],ascending=False)\n",
        "feature_importance = feature_importance[:8].sort_values(by=['importance'], ascending=False)\n",
        "\n",
        "#Visualization\n",
        "ax = feature_importance.sort_values(by=['importance'], ascending=True).plot.barh(x='feature', y='importance')\n",
        "\n",
        "plt.title('Important Feature')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuqoQ_OROQ12"
      },
      "outputs": [],
      "source": [
        "print('Train score: ' + str(lr_tuned.score(X_over_SMOTE, y_over_SMOTE))) #accuracy\n",
        "print('Test score:' + str(lr_tuned.score(X_test, y_test))) #accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9SW-5IAK-3D"
      },
      "source": [
        "### 2. Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6OLfXMvOLbQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "\n",
        "eval_classification(dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKaJjYp3OLXy"
      },
      "outputs": [],
      "source": [
        "print('Train score: ' + str(dt.score(X_over_SMOTE, y_over_SMOTE))) #accuracy\n",
        "print('Test score:' + str(dt.score(X_test, y_test))) #accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9XS0q_AK-wH"
      },
      "source": [
        "#### Tuning Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEv_yPT9OM2y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "import numpy as np\n",
        "\n",
        "# List of hyperparameter\n",
        "max_depth = [int(x) for x in np.linspace(1, 110, num = 30)] # Maximum number of levels in tree\n",
        "min_samples_split = [2, 5, 10, 100] # Minimum number of samples required to split a node\n",
        "min_samples_leaf = [1, 2, 4, 10, 20, 50] # Minimum number of samples required at each leaf node\n",
        "max_features = ['auto', 'sqrt'] # Number of features to consider at every split\n",
        "\n",
        "hyperparameters = dict(max_depth=max_depth, \n",
        "                       min_samples_split=min_samples_split, \n",
        "                       min_samples_leaf=min_samples_leaf,\n",
        "                       max_features=max_features\n",
        "                      )\n",
        "# Inisialisasi Model\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt_tuned = RandomizedSearchCV(dt, hyperparameters, cv=5, random_state=42, scoring='precision')\n",
        "dt_tuned.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "\n",
        "# Predict & Evaluation\n",
        "eval_classification(dt_tuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP5jh_s6OMzm"
      },
      "outputs": [],
      "source": [
        "# plt.figsize(10, 8)\n",
        "feat_importances = pd.Series(dt_tuned.best_estimator_.feature_importances_, index=X_over_SMOTE.columns)\n",
        "ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n",
        "ax.invert_yaxis()\n",
        "\n",
        "plt.xlabel('score')\n",
        "plt.ylabel('feature')\n",
        "plt.title('feature importance score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUeXQ1tTK-ly"
      },
      "source": [
        "### 3. Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqOmBGETOlJM"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "\n",
        "eval_classification(rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFb30d9wOk7c"
      },
      "outputs": [],
      "source": [
        "print('Train score: ' + str(rf.score(X_over_SMOTE, y_over_SMOTE))) #accuracy\n",
        "print('Test score:' + str(rf.score(X_test, y_test))) #accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSUe15TaLnlT"
      },
      "source": [
        "#### Tuning Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C8EOVwqOOtmb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "#List Hyperparameters yang akan diuji\n",
        "hyperparameters = dict(\n",
        "                       n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 20)], # Jumlah subtree \n",
        "                       bootstrap = [True], # Apakah pakai bootstrapping atau tidak\n",
        "                       criterion = ['gini','entropy'],\n",
        "                       max_depth = [int(x) for x in np.linspace(10, 110, num = 11)],  # Maximum kedalaman tree\n",
        "                       min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 10, num = 5)], # Jumlah minimum samples pada node agar boleh di split menjadi leaf baru\n",
        "                       min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 10, num = 5)], # Jumlah minimum samples pada leaf agar boleh terbentuk leaf baru\n",
        "                       max_features = ['auto', 'sqrt', 'log2'], # Jumlah feature yg dipertimbangkan pada masing-masing split\n",
        "                       n_jobs = [-1], # Core untuk parallel computation. -1 untuk menggunakan semua core\n",
        "                      )\n",
        "\n",
        "# Init\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_tuned = RandomizedSearchCV(rf, hyperparameters, cv=5, random_state=42, scoring='recall')\n",
        "rf_tuned.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "\n",
        "# Predict & Evaluation\n",
        "eval_classification(rf_tuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oxtDKYUNOtYg"
      },
      "outputs": [],
      "source": [
        "# plt.figsize(10, 8)\n",
        "feat_importances = pd.Series(rf_tuned.best_estimator_.feature_importances_, index=X_over_SMOTE.columns)\n",
        "ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n",
        "ax.invert_yaxis()\n",
        "\n",
        "plt.xlabel('score')\n",
        "plt.ylabel('feature')\n",
        "plt.title('feature importance score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-peEf_LhK-aT"
      },
      "source": [
        "### 4. AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qa2OTWkrO15Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ab = AdaBoostClassifier(random_state=42)\n",
        "ab.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "\n",
        "eval_classification(ab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VFrQo26fO1u8"
      },
      "outputs": [],
      "source": [
        "print('Train score: ' + str(ab.score(X_over_SMOTE, y_over_SMOTE))) #accuracy\n",
        "print('Test score:' + str(ab.score(X_test, y_test))) #accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCNHCiQQLozF"
      },
      "source": [
        "#### Tuning Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMIx5z87O24M"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# List of hyperparameter\n",
        "hyperparameters = dict(n_estimators = [int(x) for x in np.linspace(start = 50, stop = 2000, num = 2000)], # Jumlah iterasi\n",
        "                       learning_rate = [float(x) for x in np.linspace(start = 0.001, stop = 0.1, num = 200)],  \n",
        "                       algorithm = ['SAMME', 'SAMME.R']\n",
        "                      )\n",
        "\n",
        "# Init model\n",
        "ab = AdaBoostClassifier(random_state=42)\n",
        "ab_tuned = RandomizedSearchCV(ab, hyperparameters, random_state=42, cv=5, scoring='recall')\n",
        "ab_tuned.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "\n",
        "# Predict & Evaluation\n",
        "eval_classification(ab_tuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTqn_mo1O2s7"
      },
      "outputs": [],
      "source": [
        "print('Train score: ' + str(ab_tuned.score(X_over_SMOTE, y_over_SMOTE))) #accuracy\n",
        "print('Test score: ' + str(ab_tuned.score(X_test, y_test))) #accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POPmTTSePBc-"
      },
      "outputs": [],
      "source": [
        "# plt.figsize(10, 8)\n",
        "feat_importances = pd.Series(ab_tuned.best_estimator_.feature_importances_, index=X_over_SMOTE.columns)\n",
        "ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n",
        "ax.invert_yaxis()\n",
        "\n",
        "plt.xlabel('score')\n",
        "plt.ylabel('feature')\n",
        "plt.title('feature importance score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89MBKo-6LW7t"
      },
      "source": [
        "### 5. XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T855sSZQO3rM"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "xg = XGBClassifier(random_state=42)\n",
        "xg.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "\n",
        "eval_classification(xg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG9g9r_wPIwa"
      },
      "outputs": [],
      "source": [
        "print('Train score: ' + str(xg.score(X_over_SMOTE, y_over_SMOTE))) #accuracy\n",
        "print('Test score:' + str(xg.score(X_test, y_test))) #accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWwji0PSPIgV"
      },
      "outputs": [],
      "source": [
        "show_feature_importance(xg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLyIs5S0LqJB"
      },
      "source": [
        "#### Tuning Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "965h3sZvO4px"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "#Menjadikan ke dalam bentuk dictionary\n",
        "hyperparameters = {\n",
        "                    'max_depth' : [int(x) for x in np.linspace(10, 110, num = 11)],\n",
        "                    'min_child_weight' : [int(x) for x in np.linspace(1, 20, num = 11)],\n",
        "                    'gamma' : [float(x) for x in np.linspace(0, 1, num = 11)],\n",
        "                    'tree_method' : ['auto', 'exact', 'approx', 'hist'],\n",
        "\n",
        "                    'colsample_bytree' : [float(x) for x in np.linspace(0, 1, num = 11)],\n",
        "                    'eta' : [float(x) for x in np.linspace(0, 1, num = 100)],\n",
        "\n",
        "                    'lambda' : [float(x) for x in np.linspace(0, 1, num = 11)],\n",
        "                    'alpha' : [float(x) for x in np.linspace(0, 1, num = 11)]\n",
        "                    }\n",
        "\n",
        "# Init\n",
        "xg = XGBClassifier(random_state=42)\n",
        "xg_tuned = RandomizedSearchCV(xg, hyperparameters, cv=5, random_state=42, scoring='recall')\n",
        "xg_tuned.fit(X_over_SMOTE, y_over_SMOTE)\n",
        "\n",
        "# Predict & Evaluation\n",
        "eval_classification(xg_tuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8buXmg62O4et"
      },
      "outputs": [],
      "source": [
        "print('Train score: ' + str(xg_tuned.score(X_over_SMOTE, y_over_SMOTE))) #accuracy\n",
        "print('Test score:' + str(xg_tuned.score(X_test, y_test))) #accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fKyYgYOPVa5"
      },
      "outputs": [],
      "source": [
        "# plt.figsize(10, 8)\n",
        "feat_importances = pd.Series(xg_tuned.best_estimator_.feature_importances_, index=X_over_SMOTE.columns)\n",
        "ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n",
        "ax.invert_yaxis()\n",
        "\n",
        "plt.xlabel('score')\n",
        "plt.ylabel('feature')\n",
        "plt.title('feature importance score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAvb9Y9XLg0e"
      },
      "source": [
        "### Applied Best feature in Logistics Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q47EFohfLe0L"
      },
      "outputs": [],
      "source": [
        "# Split Feature and Label\n",
        "X_imp = X_over_SMOTE[['log_PageValues','agg_Month_Nov','log_ProductRelated','agg_TrafficType_2',\n",
        "                 'log_Informational','log_Administrative']]\n",
        "y_imp = y_over_SMOTE # target / label\n",
        "\n",
        "#Splitting the data into Train and Test\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(X_imp, y_imp, test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ4c1RKVak9d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def eval_class(model):\n",
        "    y_pred_imp = model.predict(X_test_imp)\n",
        "    print(\"Accuracy (Test Set): %.2f\" % accuracy_score(y_test_imp, y_pred_imp))\n",
        "    print(\"Precision (Test Set): %.2f\" % precision_score(y_test_imp, y_pred_imp))\n",
        "    print(\"Recall (Test Set): %.2f\" % recall_score(y_test_imp, y_pred_imp))\n",
        "    print(\"F1-Score (Test Set): %.2f\" % f1_score(y_test_imp, y_pred_imp))\n",
        "    print('AUC:'+ str(roc_auc_score(y_test_imp, y_pred_imp)))\n",
        "\n",
        "def show_feature_importance(model):\n",
        "    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "    ax = feat_importances.nlargest(25).plot(kind='barh', figsize=(10, 8))\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.xlabel('score')\n",
        "    plt.ylabel('feature')\n",
        "    plt.title('feature importance score')\n",
        "\n",
        "def show_best_hyperparameter(model, hyperparameters):\n",
        "    for key, value in hyperparameters.items() :\n",
        "        print('Best '+key+':', model.get_params()[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZQ4MP7ja3ih"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_imp = LogisticRegression(random_state=42)\n",
        "lr_imp.fit(X_train_imp,y_train_imp)\n",
        "\n",
        "eval_class(lr_imp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnfTB2lQa9Oy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Generate the confusion matrix\n",
        "y_pred_c = lr_imp.predict(X_test_imp)\n",
        "cf_matrix = confusion_matrix(y_test_imp, y_pred_c)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "group_names = ['True Negative','False Positive','False Negative','True Positive']\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "cf_matrix.flatten()]\n",
        "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
        "zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
        "ax.set_title('Confusion Matrix\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "## Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels(['False','True'])\n",
        "ax.yaxis.set_ticklabels(['False','True'])\n",
        "## Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlEvLnKObBZI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Data Science test.ipynb",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOnNwjAqgXdvsoW0Q7H941Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}